{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def filter_by_withn(tactics_df: pd.DataFrame):\n",
    "    filtered_tactics_df = pd.DataFrame(columns=tactics_df.columns.values.tolist())\n",
    "    for index, row in tactics_df.iterrows():\n",
    "        value = row['state_before']\n",
    "        if \"with\\n\" in value:\n",
    "            filtered_tactics_df.loc[len(filtered_tactics_df)] = row\n",
    "            tactics_df.drop(index=index, inplace=True)\n",
    "            print(row[\"positive\"])\n",
    "            \n",
    "        \n",
    "    return tactics_df, filtered_tactics_df\n",
    "    \n",
    "with open(\"/home/vincentzhu/gfn_ntp/data/post_verify_counting_negatives/negative_tactics_dataset.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "print(len(data))\n",
    "# print(data)\n",
    "data_df = pd.DataFrame.from_dict(data)\n",
    "# print(type(data))\n",
    "# print(data.columns.values.tolist())\n",
    "filtered_df, filtered_false_neg_df = filter_by_withn(data_df)\n",
    "# print(filtered_df)\n",
    "list_of_dicts = filtered_df.to_dict(orient='records')\n",
    "list_of_dicts2 = filtered_false_neg_df.to_dict(orient='records')\n",
    "\n",
    "# with open(\"/home/vincentzhu/gfn_ntp/data/post_verify_counting_negatives/filtered_neg_tactics_data.json\", \"w\") as f:\n",
    "#     data = json.dump(list_of_dicts, f, indent=4)\n",
    "# with open(\"/home/vincentzhu/gfn_ntp/data/post_verify_counting_negatives/filtered_false_neg_data.json\", \"w\") as f:\n",
    "#     data = json.dump(list_of_dicts2, f, indent=4)\n",
    "\n",
    "with open(\"/home/vincentzhu/gfn_ntp/data/post_verify_counting_negatives/filtered_neg_tactics_data.json\") as f:\n",
    "    data1 = json.load(f)\n",
    "with open(\"/home/vincentzhu/gfn_ntp/data/post_verify_counting_negatives/filtered_false_neg_data.json\") as f:\n",
    "    data2 = json.load(f)\n",
    "    \n",
    "print(len(data1))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original data:  12092\n",
      "Length of filtered data:  11488\n",
      "Percentage Kept:  0.9500496195831954\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer_id = \"EleutherAI/llemma_7b\"\n",
    "tokenizer_id = \"deepseek-ai/DeepSeek-Prover-V1.5-RL\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "with open(\"/home/vincentzhu/gfn_ntp/data/time_filtered_v2.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Length of original data: \", len(data))\n",
    "og_len = len(data)\n",
    "\n",
    "data_k_v = data.items()\n",
    "num_entries_to_remove = int(len(data) * 0.05)\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.tokenize(text))\n",
    "\n",
    "sorted_data = sorted(\n",
    "    data_k_v, \n",
    "    key=lambda x: count_tokens(x[1][\"traced_tactics\"][0][\"state_before\"]), \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "keys_to_remove = [key for key, _ in sorted_data[:num_entries_to_remove]]\n",
    "for key in keys_to_remove:\n",
    "    del data[key]\n",
    "\n",
    "\n",
    "print(\"Length of filtered data: \", len(data))\n",
    "print(\"Percentage Kept: \", (len(data) / og_len))\n",
    "\n",
    "with open(\"/home/vincentzhu/gfn_ntp/data/time_filtered_v3.json\", \"w\") as f:\n",
    "    data = json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11488\n",
      "0\n",
      "url https://github.com/leanprover-community/mathlib4\n",
      "commit 29dcec074de168ac2bf835a77ef68bbe069194c5\n",
      "file_path Mathlib/Data/Matrix/Block.lean\n",
      "full_name Matrix.toBlocks₂₂_diagonal\n",
      "start [310, 1]\n",
      "end [315, 61]\n",
      "traced_tactics [{'tactic': 'unfold toBlocks₂₂', 'annotated_tactic': ['unfold <a>toBlocks₂₂</a>', [{'full_name': 'Matrix.toBlocks₂₂', 'def_path': 'Mathlib/Data/Matrix/Block.lean', 'def_pos': [93, 5], 'def_end_pos': [93, 15]}]], 'state_before': \"l : Type u_1\\nm : Type u_2\\nn : Type u_3\\no : Type u_4\\np : Type u_5\\nq : Type u_6\\nm' : o → Type u_7\\nn' : o → Type u_8\\np' : o → Type u_9\\nR : Type u_10\\nS : Type u_11\\nα : Type u_12\\nβ : Type u_13\\ninst✝² : DecidableEq l\\ninst✝¹ : DecidableEq m\\ninst✝ : Zero α\\nv : l ⊕ m → α\\n⊢ (diagonal v).toBlocks₂₂ = diagonal fun i => v (Sum.inr i)\", 'state_after': \"l : Type u_1\\nm : Type u_2\\nn : Type u_3\\no : Type u_4\\np : Type u_5\\nq : Type u_6\\nm' : o → Type u_7\\nn' : o → Type u_8\\np' : o → Type u_9\\nR : Type u_10\\nS : Type u_11\\nα : Type u_12\\nβ : Type u_13\\ninst✝² : DecidableEq l\\ninst✝¹ : DecidableEq m\\ninst✝ : Zero α\\nv : l ⊕ m → α\\n⊢ (of fun i j => diagonal v (Sum.inr i) (Sum.inr j)) = diagonal fun i => v (Sum.inr i)\"}, {'tactic': 'funext i j', 'annotated_tactic': ['funext i j', []], 'state_before': \"l : Type u_1\\nm : Type u_2\\nn : Type u_3\\no : Type u_4\\np : Type u_5\\nq : Type u_6\\nm' : o → Type u_7\\nn' : o → Type u_8\\np' : o → Type u_9\\nR : Type u_10\\nS : Type u_11\\nα : Type u_12\\nβ : Type u_13\\ninst✝² : DecidableEq l\\ninst✝¹ : DecidableEq m\\ninst✝ : Zero α\\nv : l ⊕ m → α\\n⊢ (of fun i j => diagonal v (Sum.inr i) (Sum.inr j)) = diagonal fun i => v (Sum.inr i)\", 'state_after': \"case h.h\\nl : Type u_1\\nm : Type u_2\\nn : Type u_3\\no : Type u_4\\np : Type u_5\\nq : Type u_6\\nm' : o → Type u_7\\nn' : o → Type u_8\\np' : o → Type u_9\\nR : Type u_10\\nS : Type u_11\\nα : Type u_12\\nβ : Type u_13\\ninst✝² : DecidableEq l\\ninst✝¹ : DecidableEq m\\ninst✝ : Zero α\\nv : l ⊕ m → α\\ni j : m\\n⊢ of (fun i j => diagonal v (Sum.inr i) (Sum.inr j)) i j = diagonal (fun i => v (Sum.inr i)) i j\"}, {'tactic': 'simp only [ne_eq, Sum.inr.injEq, of_apply, diagonal_apply]', 'annotated_tactic': ['simp only [<a>ne_eq</a>, Sum.inr.injEq, <a>of_apply</a>, <a>diagonal_apply</a>]', [{'full_name': 'ne_eq', 'def_path': '.lake/packages/lean4/src/lean/Init/SimpLemmas.lean', 'def_pos': [89, 17], 'def_end_pos': [89, 22]}, {'full_name': 'Matrix.of_apply', 'def_path': 'Mathlib/Data/Matrix/Basic.lean', 'def_pos': [100, 9], 'def_end_pos': [100, 17]}, {'full_name': 'Matrix.diagonal_apply', 'def_path': 'Mathlib/Data/Matrix/Basic.lean', 'def_pos': [392, 9], 'def_end_pos': [392, 23]}]], 'state_before': \"case h.h\\nl : Type u_1\\nm : Type u_2\\nn : Type u_3\\no : Type u_4\\np : Type u_5\\nq : Type u_6\\nm' : o → Type u_7\\nn' : o → Type u_8\\np' : o → Type u_9\\nR : Type u_10\\nS : Type u_11\\nα : Type u_12\\nβ : Type u_13\\ninst✝² : DecidableEq l\\ninst✝¹ : DecidableEq m\\ninst✝ : Zero α\\nv : l ⊕ m → α\\ni j : m\\n⊢ of (fun i j => diagonal v (Sum.inr i) (Sum.inr j)) i j = diagonal (fun i => v (Sum.inr i)) i j\", 'state_after': 'no goals'}]\n",
      "entry_time 4.385773376910947\n",
      "entry_failed False\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "with open(\"/home/vincentzhu/gfn_ntp/data/time_filtered_v3.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "pickle_path = \"/home/vincentzhu/gfn_ntp/data/v3_wfs_pickle.pickle\"\n",
    "pickle.dump(data, open(pickle_path, \"wb\"))\n",
    "pickle.load(data, open(pickle_path, \"wb\"))\n",
    "    \n",
    "print(len(data))\n",
    "\n",
    "for k, v in data.items():\n",
    "    print(k)\n",
    "    for key, value in v.items():\n",
    "        print(key, value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer_id = \"EleutherAI/llemma_7b\"\n",
    "tokenizer_id = \"deepseek-ai/DeepSeek-Prover-V1.5-RL\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
    "\n",
    "def sample_small_test_set(data: dict, num_samples: int, seed: int = None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        \n",
    "    sampled_keys = random.sample(list(data.keys()), num_samples)\n",
    "    sampled_data = {key: data[key] for key in sampled_keys}\n",
    "    return sampled_data\n",
    "\n",
    "def first_n_thms(data: dict, num_samples: int):\n",
    "    sampled_keys = list(data.keys())[:num_samples]\n",
    "    sampled_data = {key: data[key] for key in sampled_keys}\n",
    "    return sampled_data\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.tokenize(text))\n",
    "\n",
    "with open(\"/home/vincentzhu/gfn_ntp/data/time_filtered/time_filtered_v3_wfs.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# v = data.values()\n",
    "# max_tokens = 0\n",
    "# for entry in v:\n",
    "#     max_tokens = max(count_tokens(entry[\"traced_tactics\"][0][\"state_before\"]), max_tokens)\n",
    "# print(max_tokens)\n",
    "\n",
    "# sampled_data = sample_small_test_set(data, 30, 42)\n",
    "# with open(\"/home/vincentzhu/gfn_ntp/data/time_filtered_v3_wfs_30_samples.json\", \"w\") as f:\n",
    "#     data = json.dump(sampled_data, f, indent=4)\n",
    "\n",
    "sampled_data = first_n_thms(data, 2700)\n",
    "with open(\"/home/vincentzhu/gfn_ntp/data/time_filtered/time_filtered_v3_wfs_3000.json\", \"w\") as f:\n",
    "    data = json.dump(sampled_data, f, indent=4)\n",
    "\n",
    "\n",
    "print(len(sampled_data))\n",
    "\n",
    "# print(\"Formatted with json.dumps:\")\n",
    "# print(json.dumps(sampled_data, indent=4))\n",
    "\n",
    "# sampled_data_df = pd.DataFrame.from_dict(sampled_data, orient='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

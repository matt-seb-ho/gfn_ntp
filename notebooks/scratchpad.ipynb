{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# popping from empty stack\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "# popping from empty stack\n",
    "stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(3,3)\n",
    "x[torch.randn(3,3) > 0.5] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "tensor([2, 1, 1])\n",
      "tensor([1, 2, 1])\n",
      "tensor([1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x.count_nonzero().dtype)\n",
    "print(x.count_nonzero(dim=0))\n",
    "print(x.count_nonzero(dim=1))\n",
    "print(x.count_nonzero(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([0, 1, 2, 3, 4, 5]).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so Tensor with shape (1,) can be used as an index\n",
    "x[y[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing walrus operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"abc\"\n",
    "a = 2\n",
    "b = 1\n",
    "if (a < b and (l := len(s)) > 2):\n",
    "    print(\"longer than 2\")\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 a\n",
      "2 b\n"
     ]
    }
   ],
   "source": [
    "# testing zip\n",
    "l1 = [1, 2, 3]\n",
    "l2 = ['a', 'b']\n",
    "for i, j in zip(l1, l2):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 15])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t1.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([1, 2, 3])\n",
    "t3 = torch.tensor([4, 5, 6])\n",
    "t4 = torch.stack([t2, t3], dim=-1)\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Probability Utilities Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model_hf_id = \"microsoft/phi-1_5\"\n",
    "model = AutoModelForCausalLM.from_pretrained(small_model_hf_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(small_model_hf_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id  = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch = [\n",
    "    \"Hello, my dog is cute\\n\",\n",
    "    \"Hi there!\\n\",\n",
    "]\n",
    "batch_enc = tokenizer(text_batch[0], return_tensors=\"pt\", padding=True, add_special_tokens=True)\n",
    "input_ids = batch_enc.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   616,  3290,   318, 13779,   198]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello'\n",
      "','\n",
      "' my'\n",
      "' dog'\n",
      "' is'\n",
      "' cute'\n",
      "'\\n'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(text_batch)):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tid \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mrepr\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(tid\u001b[38;5;241m.\u001b[39mitem())) )\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "for i in range(len(text_batch)):\n",
    "    for tid in input_ids[i]:\n",
    "        print(repr(tokenizer.decode(tid.item())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.log_softmax(outputs.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = probs[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 51200])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 51200])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_probs = torch.gather(probs, -1, input_ids.unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4337, -2.0271, -8.8554, -2.5866, -5.5343, -7.0558],\n",
       "        [-1.5266, -0.5090, -4.1932, -2.6174, -7.8948, -8.8712]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination_token_id = tokenizer.encode(\"\\n\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next step is to figure out how to mask out the padding tokens\n",
    "mask = (input_ids == termination_token_id).byte()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.4337,  -2.4608, -11.3162, -13.9027, -19.4370, -26.4928],\n",
       "        [ -1.5266,  -2.0355,  -6.2287,  -8.8461, -16.7409, -25.6120]],\n",
       "       grad_fn=<CumsumBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_probs.cumsum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-26.4928,  -6.2287], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_probs = torch.gather(gen_probs.cumsum(dim=-1), 1, mask.argmax(dim=-1).unsqueeze(-1))\n",
    "seq_probs.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_mask = (input_ids == termination_token_id).cumsum(dim=-1) >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False,  True],\n",
       "        [False, False,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joint sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = [1, 9, 8, 5]\n",
    "lst2 = ['a', 'b', 'c', 'd']\n",
    "paired = list(zip(lst1, lst2))\n",
    "paired.sort(key=lambda x: x[0])\n",
    "lst3, lst4 = zip(*paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 5, 8, 9), ('a', 'd', 'c', 'b'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst3, lst4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightning data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "class DummyDataModule(LightningDataModule):\n",
    "    def __init__(self, train_size=0.95, limit_theorems=100):\n",
    "        super().__init__()\n",
    "    \n",
    "    def dummy_method(self):\n",
    "        print(self.h_params.train_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

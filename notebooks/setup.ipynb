{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Lean Verifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download Model\n",
    "We discussed 2 candidate models:\n",
    "1. [LeanDojo's ReProver*](https://github.com/lean-dojo/ReProver?tab=readme-ov-file#using-trained-models-on-hugging-face)\n",
    "2. [Llemma (LM for Math)](https://huggingface.co/EleutherAI/llemma_7b)\n",
    "\n",
    "*we probably want the Lean 4 + Retiever-Less version: [hf card](https://huggingface.co/kaiyuy/leandojo-lean4-tacgen-byt5-small)\n",
    "\n",
    "ReProver is trained specially on Lean data, while Llemma is trained on various math texts, including proof assistant code (Lean, Isabelle).\n",
    "ReProver however is a ByT5-small derivative, so it only has 300M parameters. \n",
    "In comparison, Llemma is 7B model (based on CodeLlama).\n",
    "\n",
    "In the long term we probably want a richer 7B model to optimize against.\n",
    "But for initial experiments I'll start with ReProver for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewho/miniconda3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import perf_counter\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM, # Llemma\n",
    "    AutoModelForSeq2SeqLM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 25.6k/25.6k [00:00<00:00, 17.9MB/s]\n",
      "added_tokens.json: 100%|██████████| 3.02k/3.02k [00:00<00:00, 30.1MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 3.09k/3.09k [00:00<00:00, 31.5MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "config.json: 100%|██████████| 837/837 [00:00<00:00, 7.91MB/s]\n",
      "model.safetensors: 100%|██████████| 1.20G/1.20G [00:27<00:00, 43.6MB/s]\n",
      "generation_config.json: 100%|██████████| 142/142 [00:00<00:00, 1.63MB/s]\n"
     ]
    }
   ],
   "source": [
    "# this is the retriever-less version\n",
    "# - can switch \"lean4 <-> lean3\"\n",
    "reprover_model_path = \"kaiyuy/leandojo-lean4-tacgen-byt5-small\"\n",
    "reprover_tokenizer = AutoTokenizer.from_pretrained(reprover_model_path)\n",
    "reprover = AutoModelForSeq2SeqLM.from_pretrained(reprover_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tactic code example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = \"n : ℕ\\n⊢ gcd n n = n\"\n",
    "tokenized_state = reprover_tokenizer(state, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a single tactic.\n",
    "tactic_ids = reprover.generate(tokenized_state.input_ids, max_length=1024)\n",
    "tactic = reprover_tokenizer.decode(tactic_ids[0], skip_special_tokens=True)\n",
    "print(tactic, end=\"\\n\\n\")\n",
    "\n",
    "# Generate multiple tactics via beam search.\n",
    "# add timing code to get a feel for latency\n",
    "_start = perf_counter()\n",
    "tactic_candidates_ids = reprover.generate(\n",
    "    tokenized_state.input_ids,\n",
    "    max_length=1024,\n",
    "    num_beams=4,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=4,\n",
    "    early_stopping=False,\n",
    ")\n",
    "print(f\"Generated 4 candidates via beam search in {perf_counter() - _start}s\")\n",
    "tactic_candidates = reprover_tokenizer.batch_decode(\n",
    "    tactic_candidates_ids, skip_special_tokens=True\n",
    ")\n",
    "for tac in tactic_candidates:\n",
    "    print(tac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prep Data\n",
    "LeanDojo's (lean4) dataset is hosted [here](https://zenodo.org/records/10114185).\n",
    "The tar file is also copied in this repo (`REPO_ROOT/data/leandojo_benchmark_4_v5.tar.gz`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility\n",
    "REPO_ROOT = \"/mnt/hdd/msho/gfn_ntp/\"\n",
    "def full_path(path_relative_to_project_repo_root):\n",
    "    return os.path.join(REPO_ROOT, path_relative_to_project_repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's unpack the tar file\n",
    "import tarfile\n",
    "data_dir = full_path(\"data/\")\n",
    "tar_path = os.path.join(REPO_ROOT, \"data/leandojo_benchmark_4_v5.tar.gz\")\n",
    "with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
